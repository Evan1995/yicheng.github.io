<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何设置Pytorch的动态学习率]]></title>
    <url>%2F2019%2F08%2Fhow-to-set-lr-in-pytorch%2F</url>
    <content type="text"><![CDATA[本文主要涉及内容：Optimizer、_LRScheduler等源码分析。本文依旧基于Pytorch 1.1.0。 Pytorch提供了torch.optim.lr_scheduler来帮助用户改变学习率，下边将从Optimizer入手，看一下这个类是如何工作的。 Optimizer为什么从Optimizer入手，因为无论是Adam还是SGD，都是继承的这个类。同时，scheduler也是给所有的Optimizer服务的，所以需要用的方法都会定义在这个基类里，直接看一下这个类的属性即可。给出Doc中的代码链接。 首先是初始化方法def __init__(self, params, defaults)，这个方法的params参数，就是我们在初始化优化器的时候传入的网络的参数，如Alexnet.parameters()，而后边所有的参数都将合并成dict参数作为这个方法的defaults。看一下Alexnet.parameters()中存的都是什么：12for alex in Alexnet.parameters(): print(alex.shape) 可以看到，这里边存的就是整个网络的参数。有两种定义optimizer的方法： 12345optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)optimizer = optim.SGD([ &#123;'params': model.base.parameters()&#125;, &#123;'params': model.classifier.parameters(), 'lr': 1e-3&#125;], lr=1e-2, momentum=0.9) 如果是第一种定义的方法：在这个初始化方法中，会把这些参数先改造成[{&#39;params&#39;: Alexnet.parameters()}]这样的一个长度为1的list。然后对这个list进行加工，添加上defaults中的参数，如果我们使用Alexnet来做一个例子的话，就是下边这个样子：123optimizer = torch.optim.Adam(Alexnet.parameters(), lr=0.001)print([group.keys() for group in optimizer.param_groups])# [dict_keys(['params', 'lr', 'betas', 'eps', 'weight_decay', 'amsgrad'])] 如果是第二种定义的方法：因为传入的本身就是dict的形式，所以会继续对他进行加工，添加上后边的参数，我们直接看疗效：123456optimizer = torch.optim.SGD([ &#123;'params': Alexnet.features.parameters()&#125;, &#123;'params': Alexnet.classifier.parameters(), 'lr': 1e-3&#125;], lr=1e-2, momentum=0.9)print([group.keys() for group in optimizer.param_groups])# [dict_keys(['params', 'lr', 'momentum', 'dampening', 'weight_decay', 'nesterov']), dict_keys(['params', 'lr', 'momentum', 'dampening', 'weight_decay', 'nesterov'])] 这次的list变成了两个元素，而且每个元素的组成和使用Adam也不一样了，这很明显，因为不同的优化器需要的参数不同嘛~(关于不同层的lr不同的设置这里给出官网链接) 但是两者是相似的，就是每个元素都有params和lr，这就够了。 _LRScheduler所有的动态修改lr的类，都是继承的这个类，所以我们看一下这个类包含什么方法。源码链接。 在初始化方法中def __init__(self, optimizer, last_epoch=-1)，包含两个参数，第一个参数就是我们上边提到的optimizer的任何一个子类。第二个参数的意思是当前执行到了哪个epoch。我们不指定它的时候，虽然默认是-1，但是init中会调用一次step并设置为0。 一定要注意Pytorch的版本！我的windows上用的是1.0.1，服务器用的是1.1.0，就闹了很多问题。就拿这个类来说，在1.0.1中是先setp()再训练，而1.1.0进行了更新，先训练，然后再step()。 当我们调用了初始化后，会给optimizer增加一个字段，看一下：123scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)print([group.keys() for group in optimizer.param_groups])# [dict_keys(['params', 'lr', 'betas', 'eps', 'weight_decay', 'amsgrad', 'initial_lr'])] 新增加的initial_lr字段就是原始的lr。 在def step(self, epoch=None)方法中，通常情况下我们不需要指定这个参数epoch，因为每次调用他都会增加1。在这个函数中会调用一个需要重载的方法get_lr()，每次调用都会从这个方法中提取改变后的lr，赋值给optimizer。 这里其实我一直有个疑问的，就是scheduler的step和optimizer的step是一个什么关系，其实通过源码，看到这里，这俩函数没啥关系！scheduler的step只会修改lr，两者都需要执行！ 下边看一下两个scheduler的get_lr()对比一下。先看一下SetpLR：12345def get_lr(self): if (self.last_epoch == 0) or (self.last_epoch % self.step_size != 0): return [group['lr'] for group in self.optimizer.param_groups] return [group['lr'] * self.gamma for group in self.optimizer.param_groups] 这个会在设置的步长的整倍数的时候将lr*gamma。而ExponentialLR则会在每轮结束的时候都进行乘gamma的操作，这个减小也真的是指数倍的。12345def get_lr(self): if self.last_epoch == 0: return self.base_lrs return [group['lr'] * self.gamma for group in self.optimizer.param_groups] Demo12345678910scheduler = StepLR(optimizer, step_size=30, gamma=0.1)train_loader = Data.DataLoader( dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)for epoch in range(100): for X, y in train_loader: ... optimizer.zero_grad() loss.backward() optimizer.step() scheduler.step()]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Pytorch</tag>
        <tag>learning rate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch读取数据入门]]></title>
    <url>%2F2019%2F08%2Fpytorch-with-big-dataset%2F</url>
    <content type="text"><![CDATA[本文主要涉及内容：Dataset、DataLoader、DatasetFloder等相关源码分析。看了网上众多的关于这方面的文章，详细解释道理的很少，所以写了这篇文章。忽略基础知识直接进入重点点击。本文基于Pytorch 1.1.0。 基础知识可能需要导入的包 12345from torch.utils.data.dataset import Datasetimport torch.utils.data as Datafrom torchvision import transformsimport pandas as pdfrom PIL import Image Dadaset基础类首先是Dataset基础类，所有的要传入DataLoder的类都要继承这个类才行，同时必须重载__getitem__和__len__这两个方法。123456789class Dataset(object): def __getitem__(self, index): raise NotImplementedError def __len__(self): raise NotImplementedError def __add__(self, other): return ConcatDataset([self, other]) 可以看到，Dataset提供了一个__add__方法，调用的ConcatDataset简单的以list的形式，把传入的参数合并在一起。而在使用for进行遍历时，即调用ConcatDataset.__getitem__时，将传入数据按照第0维进行解包，然后排列，得到的元素的位置，即为要遍历的顺序。(目前感觉用处不大) Transforms定义Transforms可以对读入的数据进行一些变换操作，可以放下如下位置 1234567891011class MyDataset(Dataset): def __init__(self, ..., transforms=None): ... self.transforms = transforms def __getitem__(self, index): ... data = ... if self.transforms is not None: data = self.transforms(data) return data 这里的self.transforms有两层含义，一方面是可以传入一个transform，另外一方面，也可以在初始化方法中自己定义一组transform，使用链式定义的也可以，使用transforms.Compose()定义也可以。 结合Pandas读取图片可以在初始化的过程中读入csv文件，csv文件中存好相关的配置项，然后在getitem的时候在依照配置项读取图片。这样的好处是，配合DataLoader可以边读边训练，不用先花费大量时间把图片读进来在训练。 1234567891011121314151617class MyDataset(Dataset): def __init__(self, csv_path): # 读取 csv 文件 self.data_info = pd.read_csv(csv_path, header=None) # 下边可以对各个列进行解析 ... def __getitem__(self, index): # 读取图像 img_as_img = Image.open(self.image[index]) # 在csv中可以配置，是否需要额外操作 if self.operation_arr[index]: ... # 可以把图像转换成tensor，然后从csv中读取出label信息，一起返回 return (img_as_tensor, image_label) [1]中还给出了怎么从csv中读取像素值，然后转换成图片在返回，和上述过程大同小异。 但是，存在的问题是，DataLoader的shuffle还能不能用了，这个问题对训练来说非常重要。答案是可以！详情请继续读。 Dataloader配合Dataloader读取数据，for循环外可加一层循环控制epoch。 1234567if __name__ == "__main__": custom_dataset = MyDataset(...) train_loader = Data.DataLoader(dataset=custom_dataset, batch_size=BATCH_SIZE, shuffle=False) for step, (image, label) in enumerate(train_loader): ... 借鉴[3]中使用的方法，每次读取一个数据，基本可看作模仿上边过程的应用，问题是无法shuffle。 [2]中提及了一个比较完美的局部shuffle的解法，具体代码详见链接，这里对他的思想做个说明。首先，他就提到了任务和要求。任务就是数据量大，无法一次读到内存中。其次是要求，首先是每次读取一部分数据，然后是重点，能够shuffle。能否shuffle对于训练很重要。在这个任务中，把数据存在了csv中，但是从上边看，其实存储在csv中图片的路径等形式依然可以采取这种方式。 __init__方法，__init__(self,file_path,nraws,shuffle=False)，这个方法的nraws参数是用来定义每次读取多少行进行shuffle，此外，还在这个方法中计算了这个csv一共多少行。这个写法同样适用于读取图片地址。 def initial(self)在这个方法中，是现实读入nraws行，然后对着nraws进行shuffle，这个nraws应该对于batch来说稍微大一些，不然这个局部shuffle的意义就没了。比如作者在这里就使用的nraws=1000和batch_size=64。为什么不写入init中，因为这个方法每个epoch之前都要用。 __len__不用多说，直接读取计算出来的行数。 __getitem__的重载即是每次都队列的前端拿取一个元素，如果队列为空了，则重新读取一个nraws个元素。这个方法和initial共同维持了一个队列，数据结构的美妙之处。 我的想法改进读取图片的速度和totensor的转换速度共同影响了dataloader的时间，而且totensor占据了主要部分，可以在预处理的时候把所有的数据以pkl(或bin)的形式存储好，这样读取的时候直接读取的就是tensor的数据，这样可以显著加快速度。 对于[2]提出的方法，可以直接把一块数据存储成一个pkl，如1000个图片存成一个pkl，不用重新totensor，这样的整体速度会相对快，可以对这一组数据进行shuffle。这种改变不影响代码的整体结构，整体思路不变。 再改进一代目步骤(下文还会对这个步骤继续改进)： 预处理的图片totensor后全部转化成pkl，不过这次是一对一的转换，这个转化可能需要很多时间，但是这却会给以后的训练节约很多时间。 把转化后的pkl地址和label对应着存到csv中，我的路径方式是./lable/xxx.pkl，在解析的时候只需要把label和地址拼接起来即可组成正确的相对路径。此外，在这里还可以配置是否需要其他操作。用csv的形式变化更加多样，可以实现更复杂的功能。 定义一个函数，这个函数的功能是，读取这个csv文件，然后得到lenth，对这个lenth进行shuffle。 得到一个shuffle之后的序列，使用这个序列传入MyDataset，按照shuffle之后的顺序读取，再配合DataLoader即可每次都拿到shuffle之后的数据。等到这个epoch结束后，再shuffle，即可进行下次训练。 还可以先进行数据的划分，如使用scikit-learn的分层划分，然后再对train set进行shuffle。这样需要对shuffle进行改造，即不对validation set进行shuffle，这样可以实现了训练集与测试集的划分。 看源码通过看源码来获取一些新的视角，来帮助思考，DataLoader源码以及它调用的Sampler的源码。 DataLoader关于DataLoader的定义，直击要害，直接看两个最关键的点。第一段代码：1234567if batch_sampler is None: if sampler is None: if shuffle: sampler = RandomSampler(dataset) else: sampler = SequentialSampler(dataset) batch_sampler = BatchSampler(sampler, batch_size, drop_last) 这段代码解释了为啥dataset需要重载__len__，实际上是传递给了各种Sampler做下一步的处理。在DataLoader的定义中没有使用dataset的长度信息。 然后关注DataLoader中的第二段代码：12def __iter__(self): return _DataLoaderIter(self) 这个可以使得DataLoader进行迭代，即可以使用for循环。廖雪峰老师的教程里有写到，这个方法如果返回xxx，则会不断的调用xxx.__next__，廖雪峰老师说通常这个就会返回self，返回对自己的迭代，这里则直接祭出了高级用法，返回一个对象了，使用这个对象的__next__。 _DataLoaderIter可以看到，这个方法实际是我们在使用for循环的时候扮演者重要角色的大BOSS。这个方法的注释中写了大量的内容，包括数据流、多线程遇到的问题，这部分不多赘述。对于专注于单线程的我们来说，只看这一部分：123456def __next__(self): if self.num_workers == 0: # same-process loading # 前提 self.sample_iter = iter(self.batch_sampler) indices = next(self.sample_iter) # may raise StopIteration batch = self.collate_fn([self.dataset[i] for i in indices]) return batch 可以看到，它又通过batch_sampler的迭代获取序号的列表生成器，然后根据序号集合indices进行读取数据，再组合成一个batch。StopIteration这个用法真是绝了，廖雪峰老师也提到过，用for循环调用generator时，是拿到不到返回的值的，所以当报错的时候即为for循环结束的地方，也就是完成了一次epoch的训练。collate_fn是一个callable的函数，如果不传入自定义的函数，则调用默认的。如果你的合并操作需要一些特殊的操作，可以自己定义这个函数，那么可以参考官方文档，那里给出了一个例子。如果使用默认的，则直接贴出源码链接。可以看到这个默认的函数非常之强大，精通各种合并。总之，合并后的数据集是一个batch。这里是唯一一次用到__getitem__方法。下文会有分析。 BatchSamplerBatchSampler是对其他的Sampler进行了封装，代码非常简单。有意思的的关于Batchs长度的计算，用全部数据除以batch_size(单纯的觉得这里很有意思)。12345for idx in self.sampler: batch.append(idx) if len(batch) == self.batch_size: yield batch batch = [] 这段代码表示，每次从sampler中获取的都是一个序号，把这个序号组合到batch size的大小，然后yield。关于使用到的这两个Sampler。SquentialSampler就不多说了，顺序直接迭代，返回一二三四五六七。RandomSampler则是对序号打乱顺序，这里多说一点，按照这个程序中的调用，返回的是torch.randperm(n)，即n个数，没有重复的。这里的n，就是n = len(self.data_source)，也就是我们一开始重载的__len__，直到这里才起作用。此外，这个Random还支持一个叫做replacement的参数，即可以有重复的取样。这个函数还有更厉害的组合拳，可以去看源码。 思考至此，大概的脉络已经分析出来了。如何调用大数据的时候写好我们的Dataset类呢？我们可以看到两个重载的方法出现的位置，答案似乎已经清楚了，就是结合Pandas读取图片一节描述的内容。只要我们能够清楚地知道csv文件的长度，那么Dataloader就会帮我们进行shuffle，而不用我们自己进行任何操作。在读取图片的时候，也就是上文唯一提到的__getitem__出现的位置，我们只需要按照index的位置获取csv中的地址，读入图片即可，如果已经转换成了pkl，那么会大大加快我们的速度。 二代目步骤：维持一代目的1、2步骤不变，3、4的步骤可以交给DataLoader来完成了~也就是说我们只需要定义好myDataSet中的__getitem__，用好index这个关键变量，那么剩下的工作就交给DataLoader的shuffle就行了。 那么现在再来看这三个引用。ref1悄悄地告诉了我们最终结果，但是它却没有解释清楚为什么要这么用。ref2提出了一个局部shuffle的办法，也是一个不错的点子。同时也需要注意的是，这个方法中把__getitem__当作了__iter__来用，因为每次总是取队列的最顶端，没有使用到传入的index参数。 ref3最主要的问题也是没有用到index。所以ref2和ref3无论DataLoader的shuffle参数是True还是False，都无关紧要了，因为根本不会用到这个属性。 终极策略其实，上边使用csv的形式，会提供更大的可操作性，可以自己定制更加灵活的形式解决自己的问题。 但是！Pytorch早就为我们准备好了一个方便便捷的方法啦！好多盆友使用的torchvision.datasets.ImageFolder，在这里同样附上源码，这个类就是继承的同文件下的DatasetFolder，只是封装好了一组后缀，也没有提供新的方法，所以这里以DatasetFloder的源码展开看一下。 文件夹格式留意看：1234567root/class_x/xxx.extroot/class_x/xxy.extroot/class_x/xxz.extroot/class_y/123.extroot/class_y/nsdf3.extroot/class_y/asd932_.ext 首先看参数：__init__(self, root, loader, extensions=None, transform=None, target_transform=None, is_valid_file=None)：root是根路径；loader是一个callable的方法，传入一个路径，读出一个东西；ext是指定后缀；后边两个transform；最后一个参数也是一个callsble的方法，判断某个文件是否是符合我们需要的方法。下边看一下这个类的运行流程： 读入root下的文件夹的名字，将名字对应转换成数字序列（1、2、3）这种形式。也就是说，无论label怎么存，都可以！ 下边进入make_dataset这个方法，这个方法会遍历root下所有的文件，如果指定了is_valid_file则使用这个函数判断文件是否合法，否则依照传入的ext后缀判断这个文件是否是我们需要的。经过一连串的判断，最后返回N个由地址和label组成的二元tuple，N是文件个数，label是数字形式的。 在getitem时，会调用loader进行读取数据，在这里我们可以定义自己的loader。读取完后会对数据和label做transform。然后返回。如果我们自定义的loader读上来就是pkl，那么就不需要再定义transform了，非常简单。 三代目步骤：这个类把我们在再改进中的第2步骤都实现了有没有！而且还能配合上DataLoader的shuffle！现在可能只留下第1步需要我们做(如果不转pkl，那么什么也不用做，直接使用默认的loader即可)。或者我们提前把测试集和训练集划分开，然后定义两个DatasetFolder就行啦! 演示12train_dataset = Datasets.ImageFolder(img_path, transform=transforms.ToTensor())train_dataset = Datasets.DatasetFolder(img_path, extensions='pkl', loader=pklloder) 如果直接使用默认的图片后缀，如jpg、png等，可以直接使用ImageFolder即可，使用transform将读入的图片进行一些操作。因为我的图片都已经裁剪为224*224了，所以只需要totensor就行。如果像我一样使用了pkl，那么就需要自己写一个loader函数。 如果不使用shuffle，那么读入的顺序就像这样：123456789./crops/1/0044_035.pkl./crops/1/0044_036.pkl./crops/1/0044_037.pkl./crops/1/0044_038.pkl./crops/1/0044_039.pkl./crops/1/0044_040.pkl./crops/1/0044_041.pkl./crops/1/0044_042.pkl./crops/1/0044_043.pkl 如果使用了shuffle，那么就变成了这样：123456789./crops/4/0230_509.pkl./crops/1/1483_064.pkl./crops/3/1553_005.pkl./crops/2/1742_005.pkl./crops/3/1016_002.pkl./crops/4/0230_564.pkl./crops/4/2003_036.pkl./crops/2/2607_008.pkl./crops/3/0450_004.pkl 使用scikit-learn进行分层的划分数据，即按照label的比例划分：12X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, stratify=y, random_state=0) 一个224*224*3大小的图片，png要80~90kB，jpg格式的要10~30kB，而pkl的要588KB！ reference[1]PyTorch 中自定义数据集的读取方法小结[2]pytorch加载大数据[3]pytorch load huge dataset[4]Pytorch 1.1.0 Docs 在下才疏学浅，如有描述有误的地方，还望不吝赐教。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CrossEntropyLoss之我见]]></title>
    <url>%2F2019%2F08%2FCrossEntropyLoss%E4%B9%8B%E6%88%91%E8%A7%81%2F</url>
    <content type="text"><![CDATA[看了一天关于各种熵的解释，比较好的文章已经添加到了Bookmark。本文中的公式均来自Pytorch文档。 Softmax把数据缩放到$[0,1]$，且和为$1$。对每个元素进行了操作，结果并不改变维数，即输入N维，输出还是N维。 \operatorname{Softmax}\left(x_{i}\right)=\frac{\exp \left(x_{i}\right)}{\sum_{j} \exp \left(x_{j}\right)}LogSoftmax结果似乎比Softmax更加稳定，结果的范围为$[-inf,0)$。结果维数依然不变。 \log \operatorname{Softmax}\left(x_{i}\right)=\log \left(\frac{\exp \left(x_{i}\right)}{\sum_{j} \exp \left(x_{j}\right)}\right)NLLLossnegative log likelihood loss，负对数似然损失函数，对Log后的结果进行损失计算，例如Logsoftmax。l_{n}=-w_{y_n}x_{n,y_n}，如果不传入weight，那么w就是1，所以l_{n}=-x_{n,y_n}，即input的负数，reduction=mean也就变成了直接除以$N$。 \ell(x, y)=\left\{ \begin{array}{ll} {\{l_{1}, \dots, l_{N}\},} & {\text{if reduction}=\text{'none';}} \\ {\sum_{n=1}^{N} l_{n},} & {\text{if reduction}=\text {'sum';}} \\ {\sum_{n=1}^{N} \frac{1}{\sum_{n=1}^{N} w_{y_n}} l_{n},} & {\text{if reduction}=\text{'mean'.}} \\ \end{array}\right.CrossEntropyLoss关于Pytorch官网的CrossEntropyLoss补充了几组小实验。文档中给出的CrossEntropyLoss的公式如下(以下讨论的均不带weight)： \operatorname{loss}(x, class)=-\log \left(\frac{\exp (x[class])}{\sum_{j} \exp (x[j])}\right)其中的\exp (x[class])越大，就是说当这个类别对应的值越大，即占的比例越大，loss值越小，结果越靠近0。用一个样本简单模拟一下这个过程： 12345678910111213141516&gt;&gt;&gt; loss = nn.CrossEntropyLoss()&gt;&gt;&gt; input = torch.randn(1, 5, requires_grad=True)&gt;&gt;&gt; inputtensor([[-1.4976, 0.1278, 1.6863, -0.3295, 1.4173]], requires_grad=True)&gt;&gt;&gt; target = torch.empty(1, dtype=torch.long).random_(5)&gt;&gt;&gt; targettensor([3])&gt;&gt;&gt; loss(input, target)tensor(2.7809, grad_fn=&lt;NllLossBackward&gt;)&gt;&gt;&gt; i = input.detach().numpy()&gt;&gt;&gt; i = i[0]&gt;&gt;&gt; iarray([-1.4976473 , 0.12782747, 1.6863296 , -0.32949358, 1.4173082 ], dtype=float32)&gt;&gt;&gt; np.log(np.sum(np.exp(i))/np.exp(i[3]))2.7809231 文档中提到，对于多batch的情况，The losses are averaged across observations for each minibatch. 还有一句话，This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.所以上边给出的公式就是负的LogSoftmax，负号把取值区间变成了(0,inf]，越靠近0，则结果越好，这样只需要最小化loss即可，下面看一下CrossEntropyLoss源码，两者是怎么结合的： 1return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction) 先对它进行logsoftmax，然后再nllloss，默认的参数reduction=&#39;mean&#39;，所以出现了上边所说的，结果是各个minibatch的均值。下边进行一下多minibatch的实验，分别指定reduction为mean和none。 12345678910111213141516171819202122&gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)&gt;&gt;&gt; target = torch.empty(3, dtype=torch.long).random_(5)&gt;&gt;&gt; loss = nn.CrossEntropyLoss(reduction='none')&gt;&gt;&gt; loss(input, target)tensor([1.2951, 1.9074, 1.6085], grad_fn=&lt;NllLossBackward&gt;)&gt;&gt;&gt; i = input.detach().numpy()&gt;&gt;&gt; iarray([[ 1.7035984 , -0.8095179 , -0.22653757, -0.19294807, 1.0479178 ], [ 0.37498614, -0.26111123, -2.1978652 , 0.80966765, -0.5037327 ], [ 0.87008125, -1.5282617 , 0.25803488, -1.0827187 , 2.0395918 ]], dtype=float32)&gt;&gt;&gt; i=i[0]&gt;&gt;&gt; iarray([ 1.7035984 , -0.8095179 , -0.22653757, -0.19294807, 1.0479178 ], dtype=float32)&gt;&gt;&gt; targettensor([4, 1, 0])&gt;&gt;&gt; np.log(np.sum(np.exp(i))/np.exp(i[4]))1.2950675&gt;&gt;&gt; i = input.detach().numpy()[1]&gt;&gt;&gt; np.log(np.sum(np.exp(i))/np.exp(i[1]))1.9073898 可以看到，已经计算出了reduction为none时的值，下边设为mean： 12345&gt;&gt;&gt; loss_mean = nn.CrossEntropyLoss(reduction='mean')&gt;&gt;&gt; loss_mean(input, target)tensor(1.6037, grad_fn=&lt;NllLossBackward&gt;)&gt;&gt;&gt; (1.2951 + 1.9074 + 1.6085)/31.6036666666666666 恍然大悟我一直有个问题，就是交叉熵的公式分明是H(p, q)=-\sum_{x} p(x) \log q(x)，但是怎么到了CrossEntropyLoss里边$p(x)$就不见了，《经典损失函数：交叉熵》这篇文章写的非常好，不仅解释了为什么交叉熵要和Softmax一起用，而且让我明白了$p(x)$去哪了。 我直接看的是Pytorch的源码，这里给了我一点误解。这篇文章中提到，CrossEntropyLoss实际上应该是先计算Softmax，把分布转换到概率分布，得到$q(x)$，然后在计算交叉熵。在计算交叉熵的时候，$p(x)$是one-hot之后的编码，也就是说只有对应的类别的那个值是1，其他的都是0，也就得到了公式H(p, q)=- \log q(x_{class})，消去了求和记号和$p(x)$，再把q(x_{class})替换成对应的Softmax公式，即可得到了Pytorch中给出的CrossEntropyLoss公式。但是Pytorch中不是这么组织这个过程的，它是使用了$LogSoftmax+NLLLoss$的形式，其实实现的相同的方法。再次需要注意的是，NLLLoss中的1/N和\sum，是计算的不同样本之间结果，和交叉熵中的求和记号区分开。]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>loss function</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next 7.X 添加背景]]></title>
    <url>%2F2019%2F07%2FNext-7-X-%E6%B7%BB%E5%8A%A0%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[Next 7.X 添加背景跟以前的版本有了很大的变化，网上很多方法都是旧版Next的，下边是我自己尝试出来的方法：路径：themes\next\source\css\_common\scaffolding\base.styl修改其中的body，把background字段覆盖：123456// background: $body-bg-color;background: url(/images/XXX.jpg);background-size: cover;background-repeat: no-repeat;background-attachment: fixed;background-position: center; 然后如果想让前边的页面虚化一些可以在最后直接添加：123.main-inner &#123; opacity: 0.9;&#125; 最后剩下的一部分就不要虚化了，因为会导致搜索框太浅，无法使用。 如果不添加背景，可以直接给背景改个颜色，我这里最后还是采取了直接改颜色的办法，可以看到背景颜色是由$body-bg-color决定的，可以在当前主题中搜索这个关键词，例如我这个主题是Pisces，所以我的路径是在themes\next\source\css\_variables\Pisces.styl里，直接把这一项的颜色改一下就行，我改成了#f2f3f4，就是灰的颜色重了一点，可能也看不出啥变化~]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo with VSCode]]></title>
    <url>%2F2019%2F07%2FHexo-with-VSCode%2F</url>
    <content type="text"><![CDATA[介绍一下怎么在vscode中预览hexo的图片~ 本文提到的方法有两个前提：1.适用于把所有素材放到images下时；2.适用于使用NexT主题时开启了post_asset_folder功能的请参考reference的链接和本文修改。使用其他主题可以参考本文修改。 Paste Image首先需要安装插件Paste Image，这个插件是用来粘贴图片的，直接把图片复制，然后在vscode中粘贴即可，十分方便。 需要注意的是，当粘贴的时候，只需要将文件名用鼠标圈住，然后再粘贴，就可以把圈住的文件名当作粘贴后的文件名，十分方便。具体操作可见插件说明页。 安装好后在当前项目的.vscode/setting.json中写上以下配置项，这些配置项只会影响当前项目，不推荐写入系统配置项。 12345678&#123; "pasteImage.namePrefix": "$&#123;currentFileNameWithoutExt&#125;-", "pasteImage.path": "$&#123;projectRoot&#125;/source/images", "pasteImage.basePath": "$&#123;projectRoot&#125;/source", "pasteImage.forceUnixStyleSeparator": true, "pasteImage.prefix": "/", "pasteImage.insertPattern": "&#123;% fi $&#123;imageFilePath&#125;,,, %&#125;"&#125; 解释一下，意思是使用(当前文件名-圈住的名字)当前缀，然后粘贴到/images/XXX下。上个图一看： 为什么要加4个逗号，因为使用的是NexT的图片解析方式，这种解析方式只有最后一个字段是控制图片宽度的。可以搜索前一篇关于Hexo的文章看一下两者的区别。如果使用其他theme的同学可以只把&quot;pasteImage.insertPattern&quot;这一项改一下，改成对应的图片解析格式即可。 Markdown Preview Enhanced这个插件是用来预览的，支持自定义扩展，安装好后ctrl+shift+P输入Markdown Preview Enhanced: Extend Parser，修改对应部分：123456789onWillParseMarkdown: function(markdown) &#123; return new Promise((resolve, reject)=&gt; &#123; markdown = markdown.replace( /\&#123;%\s*fi\s*([\w/\.-]*)\s*,.*,.*,.*%\&#125;/g, (whole, content) =&gt; (`&lt;center&gt;&lt;img src="../$&#123;content&#125;" width="300" /&gt;&lt;/center&gt;`) ) return resolve(markdown) &#125;) &#125;, 可以看到的是，它只是使用正则，把刚才粘贴进来的格式，解析成了html显示图片的格式，宽度使用固定值300，这样即可在预览里看到刚才粘贴的图片。文件名支持.，-，数字，英文字符。这个预览的时候只是用来看一下粘贴好了没，而真正发布的时候使用的参数是md文件里写到的参数。 更新闲暇的时候现学了俩小时js，然后改了改。为什么只做了下边这几个，因为这几个参数容易控制，例如fi更容易把宽度解析出来。使用img的同学可以参考未改动之前的进行修改。12345678910111213141516onWillParseMarkdown: function(markdown) &#123; onWillParseMarkdown: function(markdown) &#123; return new Promise((resolve, reject)=&gt; &#123; markdown = markdown.replace( /\&#123;%\s*fi\s*([\w/\.-]*)\s*,.*,.*,\s*(\d*)\w*\s*%\&#125;/g, `&lt;center&gt;&lt;img src="../$1" width="$2" /&gt;&lt;/center&gt;` ).replace( /\&#123;%\s*label\s*(|default|primary|success|info|warning|danger)\s*\@\s*([\u4e00-\u9fa5]+)\s*%\&#125;/g, `==$2==` ).replace( /\&#123;%\s*note.*%\&#125;\s*\n*(.*)\n*\&#123;%\s*endnote\s*%&#125;/g, `&gt; $1` ) return resolve(markdown) &#125;) &#125;, 上边使用了一个链式得替换，逐步把markdown文件中的所需部分进行替换。一共替换了3次，则实现了3个功能： fi的解析，同时也把写好的宽度解析出来了，例如宽度是200px，200都可以 label的解析，使用这个插件进行预览的时候可以进行高亮设置，于是无论用的那个参数都进行了高亮 note缺点是note只支持一行note的解析，匹配多行调不好，但是平常用是没问题了其他的问题就诸如{\% \%}必须要连在一起写啊这都是习惯问题了，我平常习惯这么写了，这个就没改。 在这里再推荐一个Markdown All in One，功能也很强大，比如直接插入链接等，很实用。 reference《利用vscode插件与git hook提升hexo编写部署体验》link菜鸟工具，在线匹配正则，如果要修改正则的话可以用这个看看 linkw3school JavaScript replace() 方法 link $n的写法就是从这里学来的官方文档]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Build a Hexo Blog]]></title>
    <url>%2F2019%2F07%2FBuild-a-Hexo-Blog%2F</url>
    <content type="text"><![CDATA[记录一下慢慢接触Hexo中学习到的知识吧，做一个梳理。 准备工作Node.js使用的是Nodejs 10，从官网下载的时候发现Nodejs 10的支持时间还很长，所以就用的这个，第一个接触这个东西，不是很懂。 受制于用啥软件都要用最新版的强迫症思想，去查了查怎么升级Nodejs，然后node版本如何升级中提到了一句话： 爬坑后的结论：window系统升级node只能到node官网下载window安装包来覆盖之前的node。 所以安安静静的用吧，先别想着升级了，node -v查看版本，我的版本是v10.15.3。 npm下载了nodejs之后就可以用npm管理包了，同样是第一次用。类似Python的pip，安装包的。但是和pip不太一样的是，可以选择把包装在项目文件里还是装在全局，所以在安装时就会有点迷糊。 npm install xxx -g 安装在全局，可能就安装到了node的安装目录，和pip一样，安装好的项目可以全局使用，比如直接在命令行里用。如果不加-g参数就是安装到了当前项目，即在当前项目下新建一个node_modules文件夹，然后把包装进去，可以在项目代码里引入。所以安装的时候一定要注意安装位置。还可以指定-save，意思是将模块安装到项目目录下，并在package文件的dependencies节点写入依赖。关于他们的具体区别可以看这篇文章，就不多说了。有了这些知识，去看Hexo的官网的相关信息就不会迷糊了。 使用npm install npm -g命令可以方便的升级npm，这样我心里舒服多了。npm list -g --depth 0查看全局安装包，npm outdated -g --depth=0查看全局能升级的。同理，不加-g就是看当前项目的咯。npm list xxx查看某个包。 其他的用法还有uninstall/ls/update/search，详见runoob Hexo安装过程详见官网，有了上边的准备知识就不难了。安装完成后有如下几个部分： _config.yml 网站配置信息，这里边可以设置的不多，theme的设置项非常多 package.json 包信息，使用的包用了-save在这里都会有记载，所以安装包的时候只需要把使用-save，那么把当前项目写作分支同步到git后，更换设备直接安装这里边的项目即可 scaffolds 模板文件，其实就是md文件头模板吧~ source 新建的文章都在这里，还有其他资源，比如images themes 下载的主题 node_modules 安装在当前项目的包都在这里，这个在gitignore里不会同步这个文件，因为换了设备的时候使用npm重新安装即可 .gitignore 这个应该是下载hexo的时候hexo的git信息，有个问题是怎么利用这个给项目备份，换电脑了还能把这些文件恢复回来，是个问题，还在研究 从官网的配置页面很容易就能修改_config.yml文件。 命令hexo new [layout] &lt;title&gt; 新建一个文章~标题文章过长记得加引号，支持中文。 hexo generate/g 生成静态文件，可以直接部署-d/--deploy或者监视-w/--watch，监视的意思就是边改边生成静态文件~也可以用hexo server/s的形式，边改边看。 hexo deploy/d 部署，-g/--generate同时生成静态文件。g -d和d -g是一样的 hexo clean 清除缓存，清除缓存文件db.json和已生成的静态文件public hexo list &lt;type&gt; 可以查看网站的各种信息，可用的参数有page, post, route, tag, category，很好~ 写作布局有三种默认布局，post会发一个文章到博客的Archives类别里；page会新建一个标签页，和Archives是一个级别的，需要去主题页面加入生成的页面，才能正常解析，例如可以添加About me页面；draft是草稿。可以定义很多布局，比如一个categories就有一个布局，这样每次新写文章的时候直接new对应的布局就行了。据我尝试，新建的布局都会被放到_post目录下当作文章看待。 布局中的title对应着正文中文章名称，而md文件的名称则对应着url解析时对应的文章名称 草稿这个模式还挺有用的，hexo publish [layout] &lt;title&gt;可以发布写好的草稿，有些文章舍不得删除也可以直接拖进_drafts文件夹，就成了草稿，再拖回_posts就有成了可以发布的文章。hexo server --drafts可以预览草稿 分类可以使用两种分类方式，一个是categories，另外一个是tags，使用方式是有两种：12345tags/categories:- t1- t2tags/categories: [t1, t2] 区别是categories包含层级关系，tags则全是并列关系~ 正文中的标签插件这一类是hexo解析的特殊格式，可以快速在正文中插入所需的东西。算是给markdown做了个扩展吧，感觉这部分比较好。问题是很多编辑器没有办法预览这个部分，所以最好以server的形式看，也可以修改vscode中的配置信息使其兼容图片的预览。所以我更喜欢用原生markdown，除了图片可以用这个外，因为可以直接用插件预览。（vscode预览详见下一篇文章） 引用块123&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125; 别名quote，代替了&gt;的引用形式，增加了一些解释字段，内容更加丰富。 One meets its destiny on the road he takes to avoid it. Kung Fu Pandadouban 代码块123&#123;% codeblock [title] [lang:language] [url] [link text] %&#125;code snippet&#123;% endcodeblock %&#125; 别名code，相比原生代码块，增加了对引用网址等信息的解析 图片1&#123;% img [class names] /path/to/image [width] [height] [title text [alt text]] %&#125; 这个class names还是没搞懂啊，应该是对应的css文件，直接修改图片属性。路径是source目录下的图片。其实我还是更喜欢使用source/images的形式传入图片，然后![](/images/image.jpg)引入图片，问题是预览的时候根路径是当前路径，难以预览。 可以使用post_asset_folder: true设置为一个文章对应一个文件夹，这样会导致文件夹太多了，作为一个强迫症看着心里难受，还是扔一个文件夹好。在这个模式下，官方推荐使用{% asset_img name image %}方式引入图片，不会在预览的时候消失。这个命令会自动在同名文件夹下读取这个文件夹的资源了。我没这么做哦。 Link1&#123;% link text url [external] [title] %&#125; 它和默认的Link相比就是链接text之间允许空格 除了上述命令外，还有：加入一个iframe，就是嵌入一个子网页；source中的代码文件；Youtube视频；引用文章或文章中的资源等。 推送到Githubhexo clean &amp;&amp; hexo deploy，这个好像不用-g参数也会重新生成。记得推送到master分支啊，尝试推送到别的分支github.io并不会更新，这个推送了部署分支 Tip个人感觉可以直接使用下载时的gitignore，然后把项目推送到写作分支，然后再重新部署的只需要git clone下来项目文件，然后用npm install即可，因为在使用hexo建站的时候就是类似的流程，而所需的model在安装时都被记录下来了，待尝试 NexT 本文使用的均是NexT 7.X，新版本的Github和官网。 使用了NexT后，会重新解析所有布局，包括图片和quote。 1git clone https://github.com/theme-next/hexo-theme-next themes/next 目录下直接执行这个下载最新的，好处是以后可以直接用git更新~ git pull就可以更新这个主题，但是可能会遇到冲突，需要懂一点git知识，才能合并。（这个是我猜的，没试过…） Theme SettingNexT的官网的Theme setting页面做得很好，跟配置页面几乎同步在介绍各种设置的作用。下边这些都是在主题的配置页中： 修改favicon可以修改浏览器标题前的那个小图标~ 修改avatar可以放上个人的照片，等回头我拍个好的照片就放上去。 关于许可协议的介绍可以看看这个，添加许可协议 mobile_layout_economy: true 可以设置自适应窄屏 logo就是在上边添加一个logo，不能修改其他的，可能没什么用。 各种小图标来自Font Awesom v4.7，可以去这里看，然后把icon的名字记下来就行了，比如修改footer图标，我用的这个是bug。 有三种方式控制首页文章的长度，可以混合用，效果更好哦 第一种是可以设置description字段在每篇文章的开头，这个在预览的时候只会出现这句话，同时这句话还会出现在文章标题的下边 第二种是在文章任意部分添加&lt;!-- more --&gt;，就会从这里截断，这是Hexo推荐的，比如有些博主喜欢每个文章的预览都是一个图片，就可以用这个，开头放上图片，然后截断，设置项里有点开文章自动调转到这行后边的选项 第三种是在设置里设置auto_excerpt，控制字数进行截断，我主要使用的是这个 代码风格改成了night，觉得这个比较好看，其他的没有改，别的还是默认好看 busuanzi_count.enable显示访客量，这是框架自带的，不用接入什么api 搜索功能棒，很简单就可以添加本地搜索 back2top全设为true，把返回顶部的按钮从右下角改到sidebar的底端，同时显示阅读进度~ Math数学公式的支持，按照官网的要求，先卸载旧的marked，然后安装新的渲染引擎，我用的是hexo-renderer-kramed。然后只需设置math.enable=true就行，因为默认已经写了cnd加速。默认是需要在文章的开头设置mathjax: true才会对当前文章进行math渲染，也可以设置为对每一个文章都渲染，显然没啥必要。 \begin{equation} \begin{aligned} a &= b + c \\ &= d + e + f + g \\ &= h + i \end{aligned} \end{equation}标签插件NexT也提供了一套标签插件，可以看看和Hexo的哪个好用啊~这个图片突然就显示title了，不知道是我的渲染方式发生了变化还是因为引入了Fancybox。 图片的表达好像差不多，就是这个标签不带边框。note的表达更加多样性，还可以在note中使用###写入标题，最多支持三级标题，使用四级标题的时候TOC解析会出问题。对note进行如下设置：style: modern使用新式css，icons: true使用提示的图标。label就是给这段文字加个颜色。class很通用，都是这几个类别。使用了NexT后，无论哪种形式的Link都会在后边加一个小图标，很nice。Tab和Button和PDF等不常用，没写~ 123456789101112&#123;% fi /url, [alt], [title], [size] %&#125;&#123;% note [class] [no-icon] %&#125;Any content (support inline tags too.io).&#123;% endnote %&#125;[class] : default | primary | success | info | warning | danger.[no-icon] : Disable icon in note.&#123;% label [class]@Text %&#125;[class] : default | primary | success | info | warning | danger.&#123;% video url %&#125; External Libraries全部使用cdn加速Fancybox: 对图片进行jq优化，支持大图，可以点开图片后左右切换图片 ✔bookmark: 支持记录当前阅读位置，在浏览器左上角显示一个小书签，下次阅读的时候可以继续看reading_progress: 在浏览器顶端显示阅读位置Progress bar: 载入时在顶部显示进度条，可以对Ajax请求优化 ✔ (这个pace的theme咋不能用啊，这里是官网)FastClick: 优化点击动作（7.3开始删除了这个）Jquery Lazyload: 图片懒加载 ✔Canvas Nest: 背景jq，点点点点点的这个背景 ✔Canvas Ribbon: 炫酷的条带背景，每次点击鼠标就会换]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next7</tag>
      </tags>
  </entry>
</search>
